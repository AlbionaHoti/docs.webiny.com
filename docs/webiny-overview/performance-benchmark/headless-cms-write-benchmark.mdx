---
id: headless-cms-write-benchmark
title: Headless CMS - Write operation benchmark
sidebar_label: Headless CMS - Write Operation Benchmark
keywords: ["serverless", "performance", "benchmark", "headless cms", "graphql"]
description: Webiny Headless CMS performance benchmark.
---

:::tip What youâ€™ll learn

- performance of write operations on Webiny Headless CMS
- optimization suggestions

:::

## Benchmark overview

In this benchmark we are doing a GraphQL mutation request to the Headless CMS manage API. The mutation is inserting a new "Order" record and upon successful save, returning back the `id` of the new record.

Here is the full mutation that is being issued:

```graphql
mutation {
    createOrder(data:
      {
        orderId: ${OrderID}
        orderDate: "${OrderDate}"
        shippingDate: "${ShipDate}"
        unitsSold: ${UnitsSold}
        unitPrice: ${UnitPrice}
        totalPrice: ${TotalRevenue}
        country: {
          modelId: "country"
          entryId: "${Country}"
        },
        itemType: {
          modelId: "itemType"
          entryId: "${ItemType}"
        },
        salesChannel: {
          modelId: "salesChannel"
          entryId: "${SalesChannel}"
        },
        orderPriority: {
          modelId: "orderPriority"
          entryId: "${OrderPriority}"
        },
      }) {
      data {
        id
      }
      error {
        message
      }
    }
}
```

The variables are replaced with real values during the test by Apache JMeter.

:::info Content model structure

You can view the full content model structure and relations between different models on [this link here](https://raw.githubusercontent.com/webiny/benchmark/main/static/content-model-graph.png).

:::

### Test plan

We performed 3 variations of this test. The reason is that Webiny uses Elasticsearch, which is the only non-serverless infrastructure piece that's part of the architecture. Being non-serverless means we need to manually scale it. So we decided to run 3 different test variations. In each of variations we changed the load amount and the instance type.

| Test   | Number of users |              Instance               |                 Price per hour |
| ------ | :-------------: | :---------------------------------: | -----------------------------: |
| Test A |       250       | t3.small.elasticsearch (single AZ)  | <!-- prettier-ignore -->$0.038 |
| Test B |       500       | m4.xlarge.elasticsearch (multi AZ)  | <!-- prettier-ignore -->$0.369 |
| Test C |      1000       | m5.2xlarge.elasticsearch (multi AZ) | <!-- prettier-ignore -->$0.655 |

### Load structure

The test is configured by ramping up to the defined number of user threads within 25 second period. After 25 seconds we keep a steady state where the maximum amount of user threads are doing requests as fast as the system can handle for a period of 10 minutes.

## Results

### Summary

| Test   | Records inserted |              Avg response time (ms) |           Throughput (req/sec) |
| ------ | ---------------: | ----------------------------------: | -----------------------------: |
| Test A |              250 |  t3.small.elasticsearch (single AZ) | <!-- prettier-ignore -->$0.038 |
| Test B |              500 |  m4.xlarge.elasticsearch (multi AZ) | <!-- prettier-ignore -->$0.369 |
| Test C |             1000 | m5.2xlarge.elasticsearch (multi AZ) | <!-- prettier-ignore -->$0.655 |

:::info **What this means?**

TODO!!!

Requests per second is a number that helps you calculate how many users you can actually serve. The other part of that calculation is to know how your users behave. How fast they navigate between pages in this case.

As an example say your average visitors stays on your site 5 minutes, and visits around 10 pages. That's 2 pages a minute. With a throughput of 3,613req/sec, you can handle 216,780 pages a minute, or 108,390 visitors in a minute.

:::

### Response times

---

### Request flow

Each write request has the following flow:

Client -> CloudFront -> ApiGateway -> Lambda -> DynamoDB -> (async stream) -> Lambda -> Elasticsearch

Webiny writes in Elasticsearch via a DynamoDB stream, which is an asynchronous process. We do this as Elasticsearch can be a performance bottleneck and with this approach we remove it from lowering the overall throughput.

:::info About DynamoDB stream

The stream details, such as `batchSize` and `maximumBatchingWindowInSeconds` can be adjusted inside [`api/pulumi/elasticSearch.ts`](https://github.com/webiny/webiny-js/blob/next/api/pulumi/elasticSearch.ts#L95).

For additional info, check out the official [AWS guide](https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/Streams.html).

:::

An additional thing to mention is that every write request, has 1 DynamoDB write in general as we tend to do bulk writes, but there is also at least 1 read operation that happens as well. That read operation is issued by the Webiny security module to verify if the current user, or token, has the right to perform this action.

---

## Optimization suggestions

There are 3 key components that control your throughput in the basic setup.

**1. DynamoDB**

By default DynamoDB is configured with `on demand` capacity. To increase throughput, once you have a good sense of your access patters, we recommend you switch to `provisioned capacity` mode. This mode will be cheaper, if configured correctly, and more performant.

**2. Lambda concurrency**

By default your AWS account will have a soft limit of 1000 lambda concurrent executions. We recommend you increase this limit by filing a support request with AWS.

**3. Elasticsearch service**

This is the only service which is not fully serverless and needs to be manually scaled. The above numbers should help you determine how to size accordingly.

Additionally, adjusting the `batchSize` and `maximumBatchingWindowInSeconds` can also help, but this is determined by your access patterns.

---

## Cost

### Total cost

| Test   | CloudFront | ApiGateway | Lambda | DynamoDb | Total |
| ------ | ---------: | ---------: | -----: | -------: | ----: |
| Test A |        250 |        100 |    100 |      100 |   100 |
| Test B |        500 |        100 |    100 |      100 |   100 |
| Test C |       1000 |        100 |    100 |      100 |   100 |

:::caution

We only included the costs of the serverless components. The cost of the Elasticsearch service is not based on consumption, instead it's measure per hour of usage. Since all tests completed within 10 minutes and 25 seconds the cost of Elasticsearch is minimal.

That being said, on a monthly basis, non-serverless infrastructure pieces can cost 60-80% more than serverless ones.

:::

### CloudFront

| Test   | Hits |                        Traffic (GB) |                               Cost |
| ------ | ---: | ----------------------------------: | ---------------------------------: |
| Test A |  250 |  t3.small.elasticsearch (single AZ) | t3.small.elasticsearch (single AZ) |
| Test B |  500 |  m4.xlarge.elasticsearch (multi AZ) | t3.small.elasticsearch (single AZ) |
| Test C | 1000 | m5.2xlarge.elasticsearch (multi AZ) | t3.small.elasticsearch (single AZ) |

### API Gateway

| Test   | Hits |                               Cost |
| ------ | ---: | ---------------------------------: |
| Test A |  250 | t3.small.elasticsearch (single AZ) |
| Test B |  500 | t3.small.elasticsearch (single AZ) |
| Test C | 1000 | t3.small.elasticsearch (single AZ) |

### Lambda

| Test   | Requests |                       Duration (ms) |                               Cost |
| ------ | -------: | ----------------------------------: | ---------------------------------: |
| Test A |      250 |  t3.small.elasticsearch (single AZ) | t3.small.elasticsearch (single AZ) |
| Test B |      500 |  m4.xlarge.elasticsearch (multi AZ) | t3.small.elasticsearch (single AZ) |
| Test C |     1000 | m5.2xlarge.elasticsearch (multi AZ) | t3.small.elasticsearch (single AZ) |

:::info

Lambda costs also include the cost that's occurred by the DynamoDB stream.

:::

### DynamoDb

| Test   | Read ops |                           Write ops |                               Cost |
| ------ | -------: | ----------------------------------: | ---------------------------------: |
| Test A |      250 |  t3.small.elasticsearch (single AZ) | t3.small.elasticsearch (single AZ) |
| Test B |      500 |  m4.xlarge.elasticsearch (multi AZ) | t3.small.elasticsearch (single AZ) |
| Test C |     1000 | m5.2xlarge.elasticsearch (multi AZ) | t3.small.elasticsearch (single AZ) |

---

You can download and check the full report here: https://github.com/webiny/benchmark/tree/main/benchmarks/results/hc-write-benchmark
